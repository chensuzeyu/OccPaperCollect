{
    "title":  "See through the Dark: Learning Illumination-affined Representations for Nighttime Occupancy Prediction",
    "short_title":  "See through the Dark",
    "authors":  [
                    "Wuyuan",
                    "Zhiqiang Yan",
                    "Yigong Zhang",
                    "Xiang Li",
                    "Jian Yang"
                ],
    "first_author":  "Wuyuan",
    "venue":  "NeurIPS 2025",
    "presentation_type":  "poster",
    "openreview_url":  "https://openreview.net/forum?id=2Yk4GnB3DY",
    "openreview_id":  "2Yk4GnB3DY",
    "pdf_url":  "/pdf/55da50065049610ae5d89636cefc6fb6ddd81189.pdf",
    "abstract":  "Occupancy prediction aims to estimate the 3D spatial distribution of occupied regions along with their corresponding semantic labels. Existing vision-based methods perform well on daytime benchmarks but struggle in nighttime scenarios due to limited visibility and challenging lighting conditions. To address these challenges, we propose LIAR, a novel framework that learns illumination-affined representations. LIAR first introduces Selective Low-light Image Enhancement (SLLIE), which leverages the illumination priors from daytime scenes to adaptively determine whether a nighttime image is genuinely dark or sufficiently well-lit, enabling more targeted global enhancement. Building on the illumination maps generated by SLLIE, LIAR further incorporates two illumination-aware components: 2D Illumination-guided Sampling (2D-IGS) and 3D Illumination-driven Projection (3D-IDP), to respectively tackle local underexposure and overexposure. Specifically, 2D-IGS modulates feature sampling positions according to illumination maps, assigning larger offsets to darker regions and smaller ones to brighter regions, thereby alleviating feature degradation in underexposed areas. Subsequently, \n3D-IDP enhances semantic understanding in overexposed regions by constructing illumination intensity fields and supplying refined residual queries to the BEV context refinement process. Extensive experiments on both real and synthetic datasets demonstrate the superior performance of LIAR under challenging nighttime scenarios. The source code and pretrained models are available [here](https://github.com/yanzq95/LIAR).",
    "keywords":  [
                     "occupancy prediction",
                     "nighttime scenes",
                     "illumination-driven modeling"
                 ],
    "local_pdf":  "See through the Dark_NeurIPS2025.pdf"
}
